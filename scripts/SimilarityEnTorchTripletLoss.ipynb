{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SimilarityEnTorchTripletLoss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOEtJaBl60qFli0U2h4g0Bv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"elWKa7r3Mrfb"},"source":["!pip install -U fasttext pyonmttok\n","!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_QvzyMvvNFAo","executionInfo":{"status":"ok","timestamp":1627310042751,"user_tz":-120,"elapsed":7689,"user":{"displayName":"Tetyana Gavrylenko","photoUrl":"","userId":"16876190095093699565"}},"outputId":"b5b3f8c9-063e-4ffe-f875-24a0a0aca0da"},"source":["!wget -nc https://www.dropbox.com/s/c0lun02076n968t/en_tg_1101_0510.jsonl -O - | tar -xz > en_tg_1101_0510.jsonl\n","!wget https://www.dropbox.com/s/e8ewd75cc3yagim/en_vectors_v1.bin"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-07-26 14:33:55--  https://www.dropbox.com/s/c0lun02076n968t/en_tg_1101_0510.jsonl\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/c0lun02076n968t/en_tg_1101_0510.jsonl [following]\n","--2021-07-26 14:33:55--  https://www.dropbox.com/s/raw/c0lun02076n968t/en_tg_1101_0510.jsonl\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc4281e4b663ad017eadc54f60e8.dl.dropboxusercontent.com/cd/0/inline/BTCVRZdFCQ2uz4FmgKNv5cvF6DEMIbtS4wRJ4dgk8FLlLtaq99otbdy1G9BovXUIaDjBuAdcnrsHGcl621okt4em4JElecUZzrVu2oVMe9bCkMhlwRfyzOOb3BhP0LCc_ByQb3IW2qlO80oLzIL7rb3i/file# [following]\n","--2021-07-26 14:33:55--  https://uc4281e4b663ad017eadc54f60e8.dl.dropboxusercontent.com/cd/0/inline/BTCVRZdFCQ2uz4FmgKNv5cvF6DEMIbtS4wRJ4dgk8FLlLtaq99otbdy1G9BovXUIaDjBuAdcnrsHGcl621okt4em4JElecUZzrVu2oVMe9bCkMhlwRfyzOOb3BhP0LCc_ByQb3IW2qlO80oLzIL7rb3i/file\n","Resolving uc4281e4b663ad017eadc54f60e8.dl.dropboxusercontent.com (uc4281e4b663ad017eadc54f60e8.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc4281e4b663ad017eadc54f60e8.dl.dropboxusercontent.com (uc4281e4b663ad017eadc54f60e8.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1636064400 (1.5G) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","-                     0%[                    ]       0  --.-KB/s               \n","gzip: stdin: not in gzip format\n","tar: Child died with signal 13\n","tar: Error is not recoverable: exiting now\n","-                     0%[                    ]  46.80K  --.-KB/s    in 0.04s   \n","\n","\n","Cannot write to ‘-’ (Success).\n","--2021-07-26 14:33:56--  https://www.dropbox.com/s/e8ewd75cc3yagim/en_vectors_v1.bin\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/e8ewd75cc3yagim/en_vectors_v1.bin [following]\n","--2021-07-26 14:33:56--  https://www.dropbox.com/s/raw/e8ewd75cc3yagim/en_vectors_v1.bin\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com/cd/0/inline/BTDlGKEXL0UeVNdAU9MhmK2LlQMUbaFl0hb32gS8YhB33WlhFgfTIlql5K0BAh3PYkohgNdHus0Y7sddYJ8vBY-gQJB9HpBKL6B9tnDDyO1KaoCNWn1YoAq25dPPOxi-NHGtw-RBJQjP5swtO53Bw8G6/file# [following]\n","--2021-07-26 14:33:56--  https://uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com/cd/0/inline/BTDlGKEXL0UeVNdAU9MhmK2LlQMUbaFl0hb32gS8YhB33WlhFgfTIlql5K0BAh3PYkohgNdHus0Y7sddYJ8vBY-gQJB9HpBKL6B9tnDDyO1KaoCNWn1YoAq25dPPOxi-NHGtw-RBJQjP5swtO53Bw8G6/file\n","Resolving uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com (uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com (uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/BTAYBWn0edWZjUfRdhZC-OOcfq4cZuFEl-2c68-8Ij7Tjg3OemsfAnvQHBbGMikZE2L2cnc9Ryyw5tksQQtAhclcC7Cb5AhbVCP_J9NPY5Bx8VNdj-GsdJfreT3dExrhytUJvBErrYGS4NAWXSRLpwLaH4J93sVf4fUwE6RGWTfOl8-epFP7kygvrYdBwCVJPe4UfFqoEeh7PWZuWJMby35xqe063nqlxJAB7w7RSueQDsvmEDfNclDx12bMaApWgB0rNYGfuIPj24uF_65vnhostArfZQZYknOEFDzKJjzdRwcpJruZMesMrnhDU4aI99PCam2tBaJZh1ET16zVAuT7-mzZas4TVWW5C6aat6dSUNXNB7NJa0hz9p_HI-Onsds/file [following]\n","--2021-07-26 14:33:56--  https://uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com/cd/0/inline2/BTAYBWn0edWZjUfRdhZC-OOcfq4cZuFEl-2c68-8Ij7Tjg3OemsfAnvQHBbGMikZE2L2cnc9Ryyw5tksQQtAhclcC7Cb5AhbVCP_J9NPY5Bx8VNdj-GsdJfreT3dExrhytUJvBErrYGS4NAWXSRLpwLaH4J93sVf4fUwE6RGWTfOl8-epFP7kygvrYdBwCVJPe4UfFqoEeh7PWZuWJMby35xqe063nqlxJAB7w7RSueQDsvmEDfNclDx12bMaApWgB0rNYGfuIPj24uF_65vnhostArfZQZYknOEFDzKJjzdRwcpJruZMesMrnhDU4aI99PCam2tBaJZh1ET16zVAuT7-mzZas4TVWW5C6aat6dSUNXNB7NJa0hz9p_HI-Onsds/file\n","Reusing existing connection to uc7c4d62b9a1ab326b6533889b7c.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 353437130 (337M) [application/octet-stream]\n","Saving to: ‘en_vectors_v1.bin’\n","\n","en_vectors_v1.bin   100%[===================>] 337.06M  65.0MB/s    in 5.2s    \n","\n","2021-07-26 14:34:02 (65.3 MB/s) - ‘en_vectors_v1.bin’ saved [353437130/353437130]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DsTBxX1qNhrU"},"source":["!rm -f all-the-news.zip\n","!wget https://www.dropbox.com/s/y5kblk5a5x35odg/all-the-news.zip\n","!unzip all-the-news.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxR0CS0sPMSh","executionInfo":{"status":"ok","timestamp":1627310078629,"user_tz":-120,"elapsed":1184,"user":{"displayName":"Tetyana Gavrylenko","photoUrl":"","userId":"16876190095093699565"}},"outputId":"f12df02f-9b91-4a53-c669-aff99934abf2"},"source":["import fasttext\n","\n","ft_model = fasttext.load_model('en_vectors_v1.bin')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6nTcqTKDPVl5","executionInfo":{"status":"ok","timestamp":1627310089340,"user_tz":-120,"elapsed":204,"user":{"displayName":"Tetyana Gavrylenko","photoUrl":"","userId":"16876190095093699565"}}},"source":["import json\n","\n","tg_data = []\n","with open(\"en_tg_1101_0510.jsonl\", \"r\") as r:\n","    for line in r:\n","        tg_data.append(json.loads(line))\n","tg_data.sort(key=lambda x: x['timestamp'])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5FF8MRiPYqb","executionInfo":{"status":"ok","timestamp":1627310114921,"user_tz":-120,"elapsed":12800,"user":{"displayName":"Tetyana Gavrylenko","photoUrl":"","userId":"16876190095093699565"}},"outputId":"9a26a4d2-025b-41bd-fccf-f93d983c858b"},"source":["import csv\n","import sys\n","import re\n","csv.field_size_limit(sys.maxsize)\n","\n","def get_date(st):\n","    dates = re.findall(r\"\\d\\d\\d\\d\\-\\d\\d\\-\\d\\d\", st)\n","    return next(iter(dates), None)\n","\n","all_the_news_files = (\"articles1.csv\", \"articles2.csv\", \"articles3.csv\")\n","atn_data = []\n","for file_name in all_the_news_files:\n","    with open(file_name, \"r\") as r:\n","        next(r)\n","        reader = csv.reader(r, delimiter=',')\n","        for row in reader:\n","            _, _, title, host, _, date, _, _, _, text = row\n","            if date == 'nan' or get_date(date) is None:\n","                continue\n","            atn_data.append({\"title\": title, \"text\": text, \"site_name\": host, \"date\": date})\n","atn_data.sort(key=lambda x: x[\"date\"])\n","print(atn_data[0])\n","print(len(atn_data))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["{'title': 'How Nirvana’s ’Smells Like Teen Spirit’ Became An Anthem', 'text': 'In the early 1990s, Seattle stood at the center of a new rock ’n’ roll genre called grunge. The music was loud, pared down, and largely unrestrained. Hundreds of garage bands formed in Seattle over a short period of time. One of them, Nirvana, achieved mammoth success with its first   single, ”Smells Like Teen Spirit.” That song, the band and lead singer Kurt Cobain would come to represent the genre.  By the time Nirvana started playing in the small clubs around Pioneer Square in Seattle, pop music was witnessing the decline of the highly produced synthesized sound that had dominated it for years. At that time, rock subgenres were pretty  . Heavy metal was loud, and the   alternative bands from England cranked out such earnest tunes that critics called the style New Romantic music. American punk, while still vital, wasn’t commercially viable. In 1991, all that was about to change. Nirvana performed a version of ”Smells Like Teen Spirit” in front of a small crowd at the OK Hotel in Seattle. Jonathan Poneman,   of Sub Pop Records, was there. ”It started off with that chord progression, and it went into a really beautiful, almost dreamy verse,” Poneman says. ”And then they went into a bridge, which seemed to be leading to something. I mean, there was this tension in the bridge. It’s hard to explain, but then it erupted into this chorus and it was really a   experience. I believe that everybody in the room knew that they were listening to something that was truly magnificent.” ”Smells Like Teen Spirit” became an unlikely hit. It wasn’t a track designed to be marketable, or even accessible. Check out the pop charts in 1991, and you’ll find artists like Paula Abdul, Color Me Badd and Mariah Carey all dominating the Top 20. It’s the kind of music that parents could listen to with their kids. But ”Smells Like Teen Spirit” was a song that parents were going to hate. It didn’t make sense. You couldn’t understand the words, and the chorus sounded like shouting. An Unlikely Blockbuster, Nevermind, the album that included ”Smells Like Teen Spirit,” reached the top of the charts. Most ironic is that the very demographic ”Smells Like Teen Spirit” appeals to, the   slacker generation, is the subject of ridicule in the song. Singer Kurt Cobain observes his generation as ”   .” The refrain shouts, ”Here we are now, entertain us.” Nirvana crafted a cynical video to accompany the track that showed the band playing background music for a truly spirited   cheerleading squad. Almost instantly, the song was embraced as a crossover anthem. It appealed to the football players and cheerleaders just as much as it did to the   teenage punks. You could interpret it as a generation’s call to arms or a simple loud rock song. And despite massive commercial success, Nirvana managed to maintain its credibility by posing as   stars. The first time the band was featured on the cover of Rolling Stone magazine, Kurt Cobain wore a shirt that read, ”Corporate rock mags still suck.” ”There have been a lot of great and popular   bands, but there was always a feeling or a suspicion that their careers were somehow manufactured,” Poneman says. ”Nirvana was the real deal.” ”I mean, in a very short period of time, they went from playing for eight people at a small tavern in the Pioneer Square district of Seattle to playing the Coliseum, and they did it on their own terms.” And their own terms were simple: Nirvana was part of a movement that believed anyone could produce music. Neither money nor connections nor even talent were prerequisites. But for all the band’s   rock credentials, Nirvana’s legacy would have a very corporate impact on alternative rock. With its success, record companies turned grunge into one of the most profitable and   rock  . Years later, the acts that dominate the charts pose as   stars  —   and, at the same time, make a lot of money doing it.', 'site_name': 'NPR', 'date': '2000-05-15'}\n","134982\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xFdk6t4YPayV","executionInfo":{"status":"ok","timestamp":1627310114922,"user_tz":-120,"elapsed":5,"user":{"displayName":"Tetyana Gavrylenko","photoUrl":"","userId":"16876190095093699565"}}},"source":["def words_to_embed(model, words):\n","    vectors = [model.get_word_vector(w) for w in words]\n","    norm_vectors = [x / np.linalg.norm(x) for x in vectors]\n","    avg_wv = np.mean(norm_vectors, axis=0)\n","    max_wv = np.max(norm_vectors, axis=0)\n","    min_wv = np.min(norm_vectors, axis=0)\n","    return np.concatenate((avg_wv, max_wv, min_wv))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"53uA_wDyPctb","executionInfo":{"status":"ok","timestamp":1627310119222,"user_tz":-120,"elapsed":202,"user":{"displayName":"Tetyana Gavrylenko","photoUrl":"","userId":"16876190095093699565"}}},"source":["import pyonmttok\n","tokenizer = pyonmttok.Tokenizer(\"conservative\", joiner_annotate=False)\n","\n","def preprocess(text):\n","    text = str(text).strip().replace(\"\\n\", \" \").replace(\"\\xa0\", \" \").lower()\n","    tokens, _ = tokenizer.tokenize(text)\n","    text = \" \".join(tokens)\n","    return text"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHfSimf-PfGv","outputId":"56cc3f98-9590-4e9e-fb01-61a5b49efbe8"},"source":["import numpy as np\n","\n","def get_samples(data, ft_model, count, min_words=4, max_words=300):\n","    last_host_end = {}\n","    samples = []\n","    for count, row in enumerate(data[:count]):\n","        if count % 10000 == 0:\n","            print(count)\n","        \n","        host = row[\"site_name\"]\n","        text = preprocess(row[\"title\"] + \" \" + row[\"text\"])\n","        words = text.split(\" \")\n","        if len(words) < min_words:\n","            continue\n","        words = words[:max_words]\n","            \n","        border = len(words) // 2\n","        begin_words = words[:border]\n","        end_words = words[border:]\n","\n","        left_vector = words_to_embed(ft_model, begin_words)\n","        left_text = \" \".join(begin_words)\n","        right_vector = words_to_embed(ft_model, end_words)\n","        right_text = \" \".join(end_words)\n","\n","        if host in last_host_end:\n","            samples.append((left_vector, right_vector, last_host_end[host][0]))\n","        last_host_end[host] = (right_vector, right_text)\n","    return samples\n","\n","tg_samples = get_samples(tg_data, ft_model, 250000)\n","atn_samples = get_samples(atn_data, ft_model, 135000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","10000\n","20000\n","30000\n","40000\n","50000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d5vFQj0UPhuy"},"source":["tg_test_size = len(tg_samples) // 10\n","atn_test_size = len(atn_samples) // 10\n","train_samples = tg_samples[:-tg_test_size] + atn_samples[:-atn_test_size]\n","test_samples = tg_samples[-tg_test_size:] + atn_samples[-atn_test_size:]\n","tg_test_samples = tg_samples[-tg_test_size:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7ymm_X8P1p0"},"source":["from sklearn import metrics\n","from scipy import spatial\n","\n","scores = []\n","test_y = []\n","for sample in test_samples:\n","    left_vector, pos_right_vector, neg_right_vector = sample\n","    test_y += [1, 0]\n","    scores.append(-spatial.distance.cosine(left_vector, pos_right_vector))\n","    scores.append(-spatial.distance.cosine(left_vector, neg_right_vector))\n","metrics.roc_auc_score(test_y, scores)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ip4NxzesQHhp"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"l40dB2WoP3d9"},"source":["import torch\n","import torch.nn as nn\n","\n","class SiamiseModelTripletLoss(nn.Module):\n","    def __init__(self, embedding_dim=384, hidden_dim=50):\n","        super().__init__()\n","        \n","        self.mapping_layer = nn.Linear(embedding_dim, hidden_dim)\n","        self.distance = nn.PairwiseDistance(p=2)\n","        self.margin = 0.3\n","    \n","    def build_projections(self, in_vectors):\n","        projections = self.mapping_layer(in_vectors)\n","        norm = projections.norm(p=2, dim=1, keepdim=True)\n","        projections = projections.div(norm)\n","        return projections\n","\n","    def forward(self, pivot_vectors, positive_vectors, negative_vectors):\n","        pivot = self.build_projections(pivot_vectors)\n","        positive = self.build_projections(positive_vectors)\n","        negative = self.build_projections(negative_vectors)\n","        distances = self.distance(pivot, positive) - self.distance(pivot, negative) + self.margin\n","        loss = torch.mean(torch.max(distances, torch.zeros_like(distances)))\n","        return loss\n","    \n","    def apply(self, vectors):\n","        return self.build_projections(vectors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oKkkTyAEQfER"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"jyeQad7gP8eQ"},"source":["import time\n","import random\n","import torch.optim as optim\n","\n","def get_next_gen_batch(samples, batch_size=64):\n","    indices = np.arange(len(samples))\n","    np.random.shuffle(indices)\n","    batch_begin = 0\n","    while batch_begin < len(samples):\n","        batch_indices = indices[batch_begin: batch_begin + batch_size]\n","        pivot_vectors = []\n","        positive_vectors = []\n","        negative_vectors = []\n","        for data_ind in batch_indices:\n","            pivot, positive, negative = samples[data_ind]\n","            pivot_vectors.append(pivot)\n","            positive_vectors.append(positive)\n","            negative_vectors.append(negative)\n","        batch_begin += batch_size\n","        yield torch.cuda.FloatTensor(pivot_vectors), torch.cuda.FloatTensor(positive_vectors), torch.cuda.FloatTensor(negative_vectors)\n","\n","def train_model(model, train_samples, val_samples, epochs_count=10, \n","                loss_every_nsteps=10000, lr=0.01, device_name=\"cuda\"):\n","    device = torch.device(device_name)\n","    model = model.to(device)\n","    total_loss = 0\n","    start_time = time.time()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    loss_function = nn.BCELoss().cuda()\n","    prev_avg_val_loss = None\n","    for epoch in range(epochs_count):\n","        model.train()\n","        for step, (pivot, positive, negative) in enumerate(get_next_gen_batch(train_samples)):\n","            loss = model(pivot, positive, negative)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            total_loss += loss.item()\n","            if step % loss_every_nsteps == 0:\n","                val_total_loss = 0\n","                val_batch_count = 0\n","                model.eval()\n","                for _, (pivot, positive, negative) in enumerate(get_next_gen_batch(val_samples)):\n","                    val_total_loss += model(pivot, positive, negative)\n","                    val_batch_count += 1\n","                avg_val_loss = val_total_loss/val_batch_count\n","                print(\"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time))\n","                total_loss = 0\n","                start_time = time.time()\n","\n","random.shuffle(train_samples)\n","random.shuffle(test_samples)\n","model = SiamiseModelTripletLoss()\n","train_model(model, train_samples, test_samples)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P4ori-yCQL0I"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"3ZUXSoM0P-DR"},"source":["test_left = []\n","test_right = []\n","test_y = []\n","for sample in test_samples:\n","    left, pos_right, neg_right = sample\n","    test_left += [left, left]\n","    test_right += [pos_right, neg_right]\n","    test_y += [1, 0]\n","\n","batch = []\n","batch_start = 0\n","nrows = len(test_left)\n","scores = []\n","while batch_start < nrows:\n","    batch_end = batch_start + 32\n","    left_batch = test_left[batch_start: batch_end]\n","    right_batch = test_right[batch_start: batch_end]\n","    left = model.apply(torch.cuda.FloatTensor(left_batch)).cpu().detach().numpy()\n","    right = model.apply(torch.cuda.FloatTensor(right_batch)).t().cpu().detach().numpy()\n","    left = left / np.linalg.norm(left)\n","    right = right / np.linalg.norm(right)\n","    score = (left.dot(right) + 1.0) / 2.0 - 1.0\n","    score = np.diag(score)\n","    scores.extend(score.tolist())\n","    batch_start = batch_end\n","metrics.roc_auc_score(test_y, scores)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5XN6SfW9Qnfd"},"source":["# Saving"]},{"cell_type":"code","metadata":{"id":"sPM0nuWgP_8D"},"source":["model = model.cpu()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ox2TbXSKQBlT"},"source":["import torch\n","import torch.nn as nn\n","\n","class Embedder(nn.Module):\n","    def __init__(self, embedding_dim=384, hidden_dim=50):\n","        super().__init__()\n","        \n","        self.mapping_layer = nn.Linear(embedding_dim, hidden_dim)\n","    \n","    def forward(self, in_vectors):\n","        projections = self.mapping_layer(in_vectors)\n","        norm = projections.norm(p=2, dim=1, keepdim=True)\n","        projections = projections.div(norm)\n","        return projections\n","\n","examples = torch.zeros((1, 384))\n","examples[0][:] = torch.FloatTensor(test_samples[0][0])\n","embedder = Embedder()\n","embedder.mapping_layer.weight.data = model.mapping_layer.weight.data\n","embedder.mapping_layer.bias = model.mapping_layer.bias\n","traced_embedder = torch.jit.trace(embedder.cpu(), examples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kbp9v8G6QDAw"},"source":["torch.save(model.state_dict(), \"en_full_model.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gY1rK4rCQEYf"},"source":["traced_embedder.save(\"en_sentence_embedder_v1.pt\")"],"execution_count":null,"outputs":[]}]}